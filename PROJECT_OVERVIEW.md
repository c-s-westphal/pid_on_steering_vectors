# Project Overview: Steering Vectors Research Library

## ğŸ¯ Project Goals

This library implements a novel approach to steering vector research with three main innovations:

### 1. **Null-Vector Diffing Method**
Instead of requiring contrastive dataset pairs (e.g., "love" vs "hate"), we:
- Use a single concept dataset (e.g., just "dogs")
- Compute a "null vector" representing the average embedding space
- Create steering vectors by: `steering_vector = concept_activation - null_vector`

**Hypothesis**: This should capture the essence of the concept without needing an opposite.

### 2. **Novel Vector Combination Methods**
Traditional methods use simple difference: `vector_a - vector_b`

We implement and compare:
- **Mean**: `(a + b) / 2` - averages the directions
- **Max**: `elementwise_max(a, b)` - takes maximum at each dimension
- **RMS-Signed**: `sign(a+b) Â· sqrt((aÂ² + bÂ²) / 2)` - preserves magnitude information with sign
- **Diff**: `a - b` - traditional baseline

**Hypothesis**: Different combination methods may preserve information better than simple differencing.

### 3. **Comprehensive Evaluation Framework**
- Token probability shift analysis
- Concept presence scoring
- LLM-based quality evaluation
- Quantitative metrics for comparing methods

## ğŸ“ Project Structure

```
pid_on_steering_vectors/
â”œâ”€â”€ Core Library Files
â”‚   â”œâ”€â”€ models.py          # Model loading and hook management
â”‚   â”œâ”€â”€ extraction.py      # Activation extraction & null vector computation
â”‚   â”œâ”€â”€ vectors.py         # Steering vector creation & combination
â”‚   â”œâ”€â”€ steering.py        # Steered text generation
â”‚   â”œâ”€â”€ evaluation.py      # Evaluation and analysis tools
â”‚   â”œâ”€â”€ data.py           # Dataset builders and prompt templates
â”‚   â””â”€â”€ utils.py          # Utility functions
â”‚
â”œâ”€â”€ Example & Demo Scripts
â”‚   â”œâ”€â”€ example.py         # Comprehensive example workflow
â”‚   â”œâ”€â”€ interactive_demo.py # Step-by-step demo with detailed output
â”‚   â””â”€â”€ test_imports.py    # Verify installation
â”‚
â”œâ”€â”€ Documentation
â”‚   â”œâ”€â”€ README.md          # Full library documentation
â”‚   â”œâ”€â”€ GETTING_STARTED.md # Installation and quick start guide
â”‚   â””â”€â”€ PROJECT_OVERVIEW.md # This file
â”‚
â””â”€â”€ Configuration
    â”œâ”€â”€ requirements.txt   # Python dependencies
    â”œâ”€â”€ __init__.py       # Package initialization
    â””â”€â”€ .gitignore        # Git ignore rules
```

## ğŸ”¬ Research Questions

This library is designed to help answer:

### Primary Questions

1. **Does null-vector diffing work as well as traditional contrastive methods?**
   - Extract vectors using both methods
   - Compare generation quality, probability shifts
   - Measure correlation between the two approaches

2. **Which vector combination method preserves the most information?**
   - Compare mean, max, RMS-signed, and diff
   - Measure steering effectiveness for combined concepts
   - Analyze whether concepts interfere or cooperate

3. **How do steering vectors behave when combined?**
   - Can we steer toward two concepts simultaneously?
   - Does combination create emergent properties?
   - Is the relationship linear or nonlinear?

### Secondary Questions

4. **What role does the null vector play?**
   - Does it truly represent "average embedding space"?
   - How does it vary across layers?
   - Is it concept-agnostic?

5. **How do different scales affect steering?**
   - Is there an optimal scale for each concept?
   - Do scales transfer across concepts?
   - What happens at extreme scales?

6. **How layer-specific is steering?**
   - Do early/middle/late layers steer differently?
   - Is there a "sweet spot" layer?
   - Can we combine vectors from different layers?

## ğŸ§ª Experimental Workflow

### Standard Experiment Pipeline

```python
# 1. Setup
model = ModelHandler("Qwen/Qwen2.5-3B")
extractor = ActivationExtractor(model)
generator = SteeredGenerator(model)
evaluator = SteeringEvaluator(model, generator)

# 2. Create datasets
concept_dataset = DatasetBuilder.create_custom_dataset("your_concept")

# 3. Compute null vector (once per layer)
null_vector = extractor.compute_null_vector(layer_idx)

# 4. Extract concept activations
concept_activation = extractor.extract_mean_activation(
    prompts=concept_dataset.get_prompts(),
    layer_idx=layer_idx
)

# 5. Create steering vector
steering_vector = VectorComputer.from_diff_with_null(
    concept_activation=concept_activation,
    null_vector=null_vector,
    layer_idx=layer_idx,
    concept="your_concept"
)

# 6. Generate and evaluate
results = generator.compare_generations(
    prompt="test prompt",
    steering_vectors=[steering_vector],
    scales=[1.0, 2.0, 5.0]
)

# 7. Analyze
prob_analysis = evaluator.analyze_token_probability_shifts(...)
concept_scoring = evaluator.automated_concept_scoring(...)
```

## ğŸ“Š Key Features

### Activation Extraction
- âœ… Extract from any layer
- âœ… Configurable token positions (last, first, all)
- âœ… Batch processing
- âœ… Automatic hook management

### Null Vector Computation
- âœ… Average all token embeddings
- âœ… Forward pass through model
- âœ… Layer-specific null vectors
- âœ… Cached for efficiency

### Steering Vector Creation
- âœ… Null-diff method
- âœ… Traditional contrastive method
- âœ… 4 combination methods (mean, max, RMS-signed, diff)
- âœ… Save/load functionality
- âœ… Metadata tracking

### Generation & Evaluation
- âœ… Configurable steering scales
- âœ… Side-by-side comparisons
- âœ… Token probability tracking
- âœ… Concept presence scoring
- âœ… LLM-based quality judging
- âœ… JSON export for analysis

## ğŸš€ Getting Started

### Quick Install
```bash
pip install -r requirements.txt
python test_imports.py  # Verify installation
```

### Run Your First Experiment
```bash
python interactive_demo.py  # Step-by-step walkthrough
# OR
python example.py  # Full experiment with saved outputs
```

### Create Custom Concept
```python
from data import DatasetBuilder

my_concept = DatasetBuilder.create_custom_dataset(
    concept="your_topic",
    variations=["variant1", "variant2", ...]
)
```

## ğŸ“ˆ Expected Results

### What Success Looks Like

1. **Effective Steering**
   - Baseline generation is neutral
   - Steered generation mentions the concept
   - Higher scales = stronger steering

2. **Probability Shifts**
   - Concept tokens increase in probability
   - Effect scales with steering strength
   - Shifts are measurable and significant

3. **Concept Presence**
   - Steered generations score higher on concept keywords
   - Quantifiable improvement over baseline
   - Consistent across multiple prompts

### Comparison Metrics

To validate null-vector method:
- **Correlation**: Do null-diff vectors correlate with traditional vectors?
- **Effectiveness**: Do they steer equally well?
- **Efficiency**: Is single dataset sufficient?

To compare combination methods:
- **Strength**: Which produces strongest steering?
- **Coherence**: Which generates most natural text?
- **Information**: Which preserves both concepts best?

## ğŸ”§ Customization Points

### Models
Change in `models.py` or at initialization:
```python
ModelHandler(model_name="meta-llama/Llama-2-7b-hf")
```

### Layers
```python
# Try different layer ranges
early_layers = model.get_layer_range("early")
late_layers = model.get_layer_range("late")
```

### Prompts
```python
# Use different templates
dataset.get_prompts(template="question")  # vs "topic", "simple", etc.
```

### Evaluation
```python
# Custom concept keywords
evaluator.automated_concept_scoring(
    generations=results,
    concept_keywords=["custom", "keywords", "here"]
)
```

## ğŸ“ Output Files

### After Running `example.py`

```
outputs/
â”œâ”€â”€ steering_vectors/
â”‚   â”œâ”€â”€ dogs_vector.pt              # Single concept vectors
â”‚   â”œâ”€â”€ bridge_vector.pt
â”‚   â”œâ”€â”€ dogs_bridge_mean.pt         # Combined vectors
â”‚   â”œâ”€â”€ dogs_bridge_max.pt
â”‚   â”œâ”€â”€ dogs_bridge_rms.pt
â”‚   â”œâ”€â”€ dogs_bridge_diff.pt
â”‚   â””â”€â”€ traditional_diff.pt         # Baseline
â”‚
â””â”€â”€ evaluations/
    â”œâ”€â”€ dogs_probability_analysis.json
    â”œâ”€â”€ dogs_generation_quality.json
    â””â”€â”€ dogs_concept_scoring.json
```

### File Sizes
- Steering vectors: ~10-50 MB each (depends on hidden size)
- Evaluation JSONs: ~100 KB - 1 MB each

## ğŸ“ Research Applications

### For Papers/Theses
- Novel null-vector method validation
- Comprehensive comparison of combination methods
- Quantitative steering vector analysis
- Replicable experimental framework

### For Exploration
- Test different concepts and their interactions
- Explore layer-wise steering differences
- Investigate scale effects
- Discover emergent properties of combinations

### For Development
- Baseline for steering vector research
- Modular components for custom methods
- Evaluation framework for new approaches

## ğŸ“š Next Steps

1. **Install and test**: Run `interactive_demo.py`
2. **Understand workflow**: Read through `example.py`
3. **Try custom concepts**: Use `DatasetBuilder`
4. **Compare methods**: Test all combination approaches
5. **Analyze results**: Use evaluation tools
6. **Iterate**: Refine based on findings

## ğŸ¤ Contributing

Key areas for extension:
- Additional combination methods
- New evaluation metrics
- Different null vector approaches
- Multi-layer steering
- Concept arithmetic exploration

## ğŸ“– Additional Resources

- **README.md**: Detailed API documentation
- **GETTING_STARTED.md**: Installation and troubleshooting
- **Source code**: All files have extensive docstrings
- **Example scripts**: `example.py` and `interactive_demo.py`

---

**Happy researching! ğŸš€**
