"""
Example usage of the steering vectors library.

This script demonstrates:
1. Loading a model
2. Creating concept datasets
3. Extracting activations and computing null vectors
4. Creating steering vectors with different methods
5. Combining steering vectors (mean, max, RMS-signed, diff)
6. Applying steering and analyzing results
7. VALIDATING that null-vector steering actually works
8. Comparing null-diff method to traditional contrastive method
9. Evaluating probability shifts and concept presence
"""

import torch
import logging
from pathlib import Path

from models import ModelHandler
from extraction import ActivationExtractor
from vectors import VectorComputer, SteeringVector
from steering import SteeredGenerator
from evaluation import SteeringEvaluator
from data import DatasetBuilder, EvaluationPrompts

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def main():
    """Main example workflow."""

    # ============================================================================
    # 1. Setup: Load model and create components
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 1: Loading model and initializing components")
    logger.info("=" * 80)

    # Initialize model handler (defaults to Qwen2.5-3B)
    model_handler = ModelHandler(
        model_name="Qwen/Qwen2.5-3B",
        torch_dtype=torch.float16
    )

    # Create components
    extractor = ActivationExtractor(model_handler)
    generator = SteeredGenerator(model_handler)
    evaluator = SteeringEvaluator(model_handler, generator)
    vector_computer = VectorComputer()

    # Choose layers to work with (middle-late layers)
    layer_range = model_handler.get_layer_range("middle-late")
    target_layer = layer_range[len(layer_range) // 2]  # Pick middle of middle-late range
    logger.info(f"Using layer {target_layer} (from range {layer_range[0]}-{layer_range[-1]})")

    # ============================================================================
    # 2. Create datasets for concepts
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 2: Creating concept datasets")
    logger.info("=" * 80)

    # Create datasets for "dogs" and "Golden Gate Bridge"
    dogs_dataset = DatasetBuilder.create_dog_dataset()
    bridge_dataset = DatasetBuilder.create_bridge_dataset()

    logger.info(f"Dogs dataset: {dogs_dataset}")
    logger.info(f"Example prompts: {dogs_dataset.get_prompts()[:3]}")

    logger.info(f"Bridge dataset: {bridge_dataset}")
    logger.info(f"Example prompts: {bridge_dataset.get_prompts()[:3]}")

    # ============================================================================
    # 3. Compute null vector
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 3: Computing null vector")
    logger.info("=" * 80)

    # Use "zeros" method - no subtraction, just raw activations
    # This avoids the null vector dominating the steering vector
    null_vector = extractor.compute_null_vector(target_layer, method="zeros")
    logger.info(f"Null vector shape: {null_vector.shape}")
    logger.info(f"Null vector norm: {torch.norm(null_vector).item():.4f}")
    logger.info("Note: Using zeros method (raw activations, no null subtraction)")

    # ============================================================================
    # 4. Extract activations for concepts
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 4: Extracting activations for concepts")
    logger.info("=" * 80)

    # Get prompts
    dogs_prompts = dogs_dataset.get_prompts()
    bridge_prompts = bridge_dataset.get_prompts()

    # Extract mean activations
    logger.info("Extracting activations for 'dogs' concept...")
    dogs_activation = extractor.extract_mean_activation(
        prompts=dogs_prompts,
        layer_idx=target_layer,
        position="last"
    )
    logger.info(f"Dogs activation shape: {dogs_activation.shape}")
    logger.info(f"Dogs activation norm: {torch.norm(dogs_activation).item():.4f}")

    logger.info("Extracting activations for 'Golden Gate Bridge' concept...")
    bridge_activation = extractor.extract_mean_activation(
        prompts=bridge_prompts,
        layer_idx=target_layer,
        position="last"
    )
    logger.info(f"Bridge activation shape: {bridge_activation.shape}")
    logger.info(f"Bridge activation norm: {torch.norm(bridge_activation).item():.4f}")

    # ============================================================================
    # 5. Create steering vectors using null-diff method
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 5: Creating steering vectors (null-diff method)")
    logger.info("=" * 80)

    dogs_vector = vector_computer.from_diff_with_null(
        concept_activation=dogs_activation,
        null_vector=null_vector,
        layer_idx=target_layer,
        concept="dogs"
    )
    logger.info(f"Dogs steering vector: {dogs_vector}")
    logger.info(f"Dogs steering vector norm: {torch.norm(dogs_vector.vector).item():.4f}")

    bridge_vector = vector_computer.from_diff_with_null(
        concept_activation=bridge_activation,
        null_vector=null_vector,
        layer_idx=target_layer,
        concept="golden_gate_bridge"
    )
    logger.info(f"Bridge steering vector: {bridge_vector}")
    logger.info(f"Bridge steering vector norm: {torch.norm(bridge_vector.vector).item():.4f}")

    # ============================================================================
    # 6. Create combined steering vectors
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 6: Creating combined steering vectors")
    logger.info("=" * 80)

    # Traditional diff baseline
    traditional_diff = vector_computer.from_traditional_diff(
        activation_a=dogs_activation,
        activation_b=bridge_activation,
        layer_idx=target_layer,
        concept="dogs vs bridge (traditional)"
    )
    logger.info(f"Traditional diff: {traditional_diff}")

    # Mean combination
    mean_combined = vector_computer.combine_vectors(
        vector_a=dogs_vector,
        vector_b=bridge_vector,
        method="mean",
        concept="dogs + bridge (mean)"
    )
    logger.info(f"Mean combined: {mean_combined}")

    # Max combination
    max_combined = vector_computer.combine_vectors(
        vector_a=dogs_vector,
        vector_b=bridge_vector,
        method="max",
        concept="dogs + bridge (max)"
    )
    logger.info(f"Max combined: {max_combined}")

    # RMS-signed combination
    rms_combined = vector_computer.combine_vectors(
        vector_a=dogs_vector,
        vector_b=bridge_vector,
        method="rms_signed",
        concept="dogs + bridge (rms_signed)"
    )
    logger.info(f"RMS-signed combined: {rms_combined}")

    # Diff combination
    diff_combined = vector_computer.combine_vectors(
        vector_a=dogs_vector,
        vector_b=bridge_vector,
        method="diff",
        concept="dogs - bridge (diff)"
    )
    logger.info(f"Diff combined: {diff_combined}")

    # ============================================================================
    # 7. Save steering vectors
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 7: Saving steering vectors")
    logger.info("=" * 80)

    output_dir = Path("outputs/steering_vectors")
    output_dir.mkdir(parents=True, exist_ok=True)

    dogs_vector.save(output_dir / "dogs_vector.pt")
    bridge_vector.save(output_dir / "bridge_vector.pt")
    mean_combined.save(output_dir / "dogs_bridge_mean.pt")
    max_combined.save(output_dir / "dogs_bridge_max.pt")
    rms_combined.save(output_dir / "dogs_bridge_rms.pt")
    diff_combined.save(output_dir / "dogs_bridge_diff.pt")
    traditional_diff.save(output_dir / "traditional_diff.pt")

    logger.info(f"Saved all steering vectors to {output_dir}")

    # ============================================================================
    # 8. Test generation with steering
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 8: Testing generation with steering vectors")
    logger.info("=" * 80)

    # Get neutral prompts for testing
    test_prompts = EvaluationPrompts.get_neutral_prompts()[:3]

    for prompt in test_prompts:
        logger.info(f"\nTest prompt: '{prompt}'")
        logger.info("-" * 60)

        # Compare generations
        comparison = generator.compare_generations(
            prompt=prompt,
            steering_vectors=[dogs_vector, bridge_vector, mean_combined],
            scales=[1.5, 1.5, 1.5],  # Subtle steering to retain model capability
            max_new_tokens=30
        )

        logger.info(f"Baseline: {comparison['baseline']['text']}")
        for steered in comparison['steered']:
            logger.info(f"{steered['steering_info']['concept']}: {steered['text']}")

    # ============================================================================
    # 9. TEST MULTIPLE SCALES FOR ALL COMBINATION METHODS
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 9: Testing multiple scales for all combination methods")
    logger.info("=" * 80)

    # Test scales
    test_scales = [0.1, 0.3, 0.5, 0.7, 1.0, 1.5, 2.0]
    test_prompt_scale = "Write a short paragraph about"

    # All vectors to test
    all_vectors = [
        ("Dogs (null-diff)", dogs_vector),
        ("Bridge (null-diff)", bridge_vector),
        ("Mean combination", mean_combined),
        ("Max combination", max_combined),
        ("RMS-signed combination", rms_combined),
        ("Diff combination", diff_combined),
        ("Traditional contrastive", traditional_diff),
    ]

    logger.info(f"\nTest prompt: '{test_prompt_scale}'")
    logger.info(f"Testing scales: {test_scales}\n")

    # Generate baseline once
    logger.info("BASELINE (no steering):")
    logger.info("-" * 60)
    baseline_scale = generator.generate(
        prompt=test_prompt_scale,
        steering_vector=None,
        max_new_tokens=40,
        temperature=0.7
    )
    logger.info(f"{baseline_scale['text']}\n")

    # Test each vector at each scale
    for vec_name, vec in all_vectors:
        logger.info("=" * 60)
        logger.info(f"VECTOR: {vec_name}")
        logger.info(f"Vector norm: {torch.norm(vec.vector).item():.2f}")
        logger.info("=" * 60)

        for scale in test_scales:
            result = generator.generate(
                prompt=test_prompt_scale,
                steering_vector=vec,
                scale=scale,
                max_new_tokens=40,
                temperature=0.7
            )

            # Check for garbled output
            text = result['text']
            has_control_chars = any(ord(c) < 32 and c not in '\n\t' for c in text)

            if has_control_chars:
                logger.info(f"\nScale {scale}: ‚ö†Ô∏è GARBLED OUTPUT")
                logger.info(f"  {text[:80]}...")
            else:
                # Count concept mentions
                dog_words = ['dog', 'dogs', 'puppy', 'puppies', 'canine', 'pet']
                bridge_words = ['bridge', 'golden', 'gate', 'san francisco']
                dog_count = sum(text.lower().count(word) for word in dog_words)
                bridge_count = sum(text.lower().count(word) for word in bridge_words)

                logger.info(f"\nScale {scale}: ‚úì Valid (dog:{dog_count}, bridge:{bridge_count})")
                logger.info(f"  {text[:80]}...")

        logger.info("")  # Blank line between vectors

    logger.info("=" * 80)
    logger.info("SCALE TESTING SUMMARY")
    logger.info("=" * 80)
    logger.info("Review the outputs above to identify:")
    logger.info("1. Which scales work best for each combination method")
    logger.info("2. When garbled output starts (scale too high)")
    logger.info("3. How different methods compare at same scale")
    logger.info("4. Optimal scale range for your vectors")
    logger.info("=" * 80 + "\n")

    # ============================================================================
    # 10. VALIDATE NULL-VECTOR METHOD: Compare to traditional contrastive method
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 10: VALIDATING NULL-VECTOR METHOD")
    logger.info("=" * 80)
    logger.info("\nThis step verifies that null-vector steering actually works")
    logger.info("by comparing it to the traditional contrastive method.\n")

    # Test both methods on the same neutral prompts
    validation_prompts = [
        "Let me tell you about",
        "Today I want to discuss",
        "An interesting fact is that"
    ]

    logger.info("Comparing null-diff vs traditional contrastive methods:")
    logger.info("-" * 60)

    for prompt in validation_prompts:
        logger.info(f"\nPrompt: '{prompt}'")

        # Generate baseline
        baseline = generator.generate(
            prompt=prompt,
            steering_vector=None,
            max_new_tokens=25,
            temperature=0.7
        )

        # Generate with null-diff dogs vector
        null_diff_gen = generator.generate(
            prompt=prompt,
            steering_vector=dogs_vector,
            scale=1.5,
            max_new_tokens=25,
            temperature=0.7
        )

        # Generate with traditional diff
        trad_diff_gen = generator.generate(
            prompt=prompt,
            steering_vector=traditional_diff,
            scale=1.5,
            max_new_tokens=25,
            temperature=0.7
        )

        logger.info(f"  Baseline:        {baseline['text'][:80]}...")
        logger.info(f"  Null-diff (dogs): {null_diff_gen['text'][:80]}...")
        logger.info(f"  Traditional diff: {trad_diff_gen['text'][:80]}...")

    # Quantitative validation: Check probability shifts
    logger.info("\n" + "=" * 60)
    logger.info("QUANTITATIVE VALIDATION: Token Probability Shifts")
    logger.info("=" * 60)

    validation_prompt = "Let me tell you about"
    dog_tokens_short = ["dog", "dogs", "puppy"]

    # Check null-diff method
    logger.info("\nNull-diff method (dogs vector):")
    null_prob_result = evaluator.analyze_token_probability_shifts(
        prompt=validation_prompt,
        steering_vector=dogs_vector,
        concept_tokens=dog_tokens_short,
        scales=[2.0],
        max_new_tokens=5
    )

    if 'statistics' in null_prob_result and 'per_token' in null_prob_result['statistics']:
        for token, stats in null_prob_result['statistics']['per_token'].items():
            baseline_prob = stats['baseline_avg_prob']
            if 'scale_effects' in stats and 2.0 in stats['scale_effects']:
                steered_prob = stats['scale_effects'][2.0]['avg_prob']
                change = stats['scale_effects'][2.0]['relative_change'] * 100
                logger.info(f"  '{token}': {baseline_prob:.6f} ‚Üí {steered_prob:.6f} ({change:+.1f}%)")

    # Success criteria
    logger.info("\n" + "=" * 60)
    logger.info("VALIDATION RESULTS:")
    logger.info("=" * 60)

    # Check if steering increased concept token probabilities
    success = False
    if 'statistics' in null_prob_result and 'per_token' in null_prob_result['statistics']:
        increases = []
        for token, stats in null_prob_result['statistics']['per_token'].items():
            if 'scale_effects' in stats and 2.0 in stats['scale_effects']:
                change = stats['scale_effects'][2.0]['relative_change']
                increases.append(change > 0)

        success = any(increases)

    if success:
        logger.info("‚úÖ SUCCESS: Null-vector steering WORKS!")
        logger.info("   - Dog-related tokens increased in probability")
        logger.info("   - Generations show concept-related content")
        logger.info("   - Null-diff method is validated!")
    else:
        logger.info("‚ö†Ô∏è  WARNING: Null-vector steering may need tuning")
        logger.info("   - Try different scales or layers")
        logger.info("   - Check that concept activations are distinct from null")

    # ============================================================================
    # 11. Analyze probability shifts in detail
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 11: Analyzing probability shifts for concept tokens (detailed)")
    logger.info("=" * 80)

    # Define concept-related tokens to track
    dog_tokens = ["dog", "dogs", "puppy", "puppies", "canine", "pet"]
    bridge_tokens = ["bridge", "Golden", "Gate", "San", "Francisco"]

    # Test a neutral prompt
    test_prompt = "Let me tell you about"

    # Analyze dogs vector
    logger.info("\nAnalyzing probability shifts for 'dogs' steering vector...")
    dogs_prob_analysis = evaluator.analyze_token_probability_shifts(
        prompt=test_prompt,
        steering_vector=dogs_vector,
        concept_tokens=dog_tokens,
        scales=[1.0, 2.0, 5.0],
        max_new_tokens=10
    )

    # Print statistics
    if 'statistics' in dogs_prob_analysis and 'per_token' in dogs_prob_analysis['statistics']:
        logger.info("\nProbability statistics for dog-related tokens:")
        for token, stats in dogs_prob_analysis['statistics']['per_token'].items():
            logger.info(f"\n  Token: '{token}'")
            logger.info(f"  Baseline avg prob: {stats['baseline_avg_prob']:.6f}")
            if 'scale_effects' in stats:
                for scale, effect in stats['scale_effects'].items():
                    logger.info(f"    Scale {scale}: {effect['avg_prob']:.6f} "
                              f"(change: {effect['absolute_change']:+.6f}, "
                              f"{effect['relative_change']*100:+.2f}%)")

    # ============================================================================
    # 12. Evaluate concept presence
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 12: Evaluating concept presence in generations")
    logger.info("=" * 80)

    # Generate multiple samples
    eval_prompts = EvaluationPrompts.get_neutral_prompts()[:5]

    logger.info(f"\nGenerating {len(eval_prompts)} samples with dogs steering...")
    dogs_quality = evaluator.evaluate_generation_quality(
        prompts=eval_prompts,
        steering_vector=dogs_vector,
        scale=1.5,
        max_new_tokens=50
    )

    # Score for concept presence
    scoring = evaluator.automated_concept_scoring(
        generations=dogs_quality['generations'],
        concept_keywords=dog_tokens
    )

    logger.info("\nConcept presence scoring results:")
    if 'baseline_avg' in scoring:
        logger.info(f"Baseline - Avg occurrences: {scoring['baseline_avg']['avg_total_occurrences']:.2f}, "
                   f"Presence rate: {scoring['baseline_avg']['avg_presence_rate']:.4f}")
    if 'steered_avg' in scoring:
        logger.info(f"Steered - Avg occurrences: {scoring['steered_avg']['avg_total_occurrences']:.2f}, "
                   f"Presence rate: {scoring['steered_avg']['avg_presence_rate']:.4f}")

    # ============================================================================
    # 13. Save evaluation results
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 13: Saving evaluation results")
    logger.info("=" * 80)

    eval_output_dir = Path("outputs/evaluations")
    eval_output_dir.mkdir(parents=True, exist_ok=True)

    evaluator.save_evaluation_results(
        dogs_prob_analysis,
        eval_output_dir / "dogs_probability_analysis.json"
    )

    evaluator.save_evaluation_results(
        dogs_quality,
        eval_output_dir / "dogs_generation_quality.json"
    )

    evaluator.save_evaluation_results(
        scoring,
        eval_output_dir / "dogs_concept_scoring.json"
    )

    logger.info(f"Saved evaluation results to {eval_output_dir}")

    # ============================================================================
    # 14. FINAL SUMMARY OF RESULTS
    # ============================================================================
    logger.info("=" * 80)
    logger.info("STEP 14: FINAL SUMMARY OF RESULTS")
    logger.info("=" * 80)

    logger.info("\n" + "=" * 60)
    logger.info("MODEL & CONFIGURATION")
    logger.info("=" * 60)
    logger.info(f"Model: {model_handler.model_name}")
    logger.info(f"Target layer: {target_layer} (out of {model_handler.num_layers} layers)")
    logger.info(f"Hidden size: {model_handler.hidden_size}")

    logger.info("\n" + "=" * 60)
    logger.info("NULL VECTOR")
    logger.info("=" * 60)
    logger.info(f"Null vector norm: {torch.norm(null_vector).item():.4f}")
    logger.info(f"Method: Average of all {model_handler.tokenizer.vocab_size} token embeddings")

    logger.info("\n" + "=" * 60)
    logger.info("STEERING VECTORS CREATED")
    logger.info("=" * 60)
    logger.info(f"1. Dogs (null-diff):          norm = {torch.norm(dogs_vector.vector).item():.4f}")
    logger.info(f"2. Bridge (null-diff):        norm = {torch.norm(bridge_vector.vector).item():.4f}")
    logger.info(f"3. Mean combination:          norm = {torch.norm(mean_combined.vector).item():.4f}")
    logger.info(f"4. Max combination:           norm = {torch.norm(max_combined.vector).item():.4f}")
    logger.info(f"5. RMS-signed combination:    norm = {torch.norm(rms_combined.vector).item():.4f}")
    logger.info(f"6. Diff combination:          norm = {torch.norm(diff_combined.vector).item():.4f}")
    logger.info(f"7. Traditional contrastive:   norm = {torch.norm(traditional_diff.vector).item():.4f}")

    logger.info("\n" + "=" * 60)
    logger.info("VALIDATION RESULTS")
    logger.info("=" * 60)
    if success:
        logger.info("‚úÖ NULL-VECTOR METHOD VALIDATED")
        logger.info("   Null-diff steering successfully increased concept token probabilities")
    else:
        logger.info("‚ö†Ô∏è  Validation inconclusive - may need parameter tuning")

    # Show validation numbers if available
    if 'statistics' in null_prob_result and 'per_token' in null_prob_result['statistics']:
        logger.info("\n   Concept-related token probability increases:")
        logger.info("   (measuring probability of dog-related tokens)")
        for token, stats in null_prob_result['statistics']['per_token'].items():
            if 'scale_effects' in stats and 2.0 in stats['scale_effects']:
                change = stats['scale_effects'][2.0]['relative_change'] * 100
                if change > 0:
                    logger.info(f"     '{token}': +{change:.1f}%")

    logger.info("\n" + "=" * 60)
    logger.info("EXAMPLE GENERATIONS FOR EACH STEERING VECTOR")
    logger.info("=" * 60)
    logger.info("Prompt: 'Write a paragraph about something you're interested in.'\n")

    example_prompt = "Write a paragraph about something you're interested in."

    # Baseline
    logger.info("Baseline (no steering):")
    baseline_example = generator.generate(
        prompt=example_prompt,
        steering_vector=None,
        max_new_tokens=60,
        temperature=0.7
    )
    logger.info(f"  {baseline_example['text']}\n")

    # Dogs vector
    logger.info("Dogs steering (null-diff, scale=1.5):")
    dogs_example = generator.generate(
        prompt=example_prompt,
        steering_vector=dogs_vector,
        scale=1.5,
        max_new_tokens=60,
        temperature=0.7
    )
    logger.info(f"  {dogs_example['text']}\n")

    # Bridge vector
    logger.info("Bridge steering (null-diff, scale=1.5):")
    bridge_example = generator.generate(
        prompt=example_prompt,
        steering_vector=bridge_vector,
        scale=1.5,
        max_new_tokens=60,
        temperature=0.7
    )
    logger.info(f"  {bridge_example['text']}\n")

    # Mean combination
    logger.info("Mean combination (dogs + bridge, scale=1.5):")
    mean_example = generator.generate(
        prompt=example_prompt,
        steering_vector=mean_combined,
        scale=1.5,
        max_new_tokens=60,
        temperature=0.7
    )
    logger.info(f"  {mean_example['text']}\n")

    # Max combination
    logger.info("Max combination (elementwise_max, scale=1.5):")
    max_example = generator.generate(
        prompt=example_prompt,
        steering_vector=max_combined,
        scale=1.5,
        max_new_tokens=60,
        temperature=0.7
    )
    logger.info(f"  {max_example['text']}\n")

    # RMS-signed combination
    logger.info("RMS-signed combination (scale=1.5):")
    rms_example = generator.generate(
        prompt=example_prompt,
        steering_vector=rms_combined,
        scale=1.5,
        max_new_tokens=60,
        temperature=0.7
    )
    logger.info(f"  {rms_example['text']}\n")

    # Diff combination
    logger.info("Diff combination (dogs - bridge, scale=1.5):")
    diff_example = generator.generate(
        prompt=example_prompt,
        steering_vector=diff_combined,
        scale=1.5,
        max_new_tokens=60,
        temperature=0.7
    )
    logger.info(f"  {diff_example['text']}\n")

    # Traditional diff
    logger.info("Traditional contrastive (dogs vs bridge, scale=1.5):")
    trad_example = generator.generate(
        prompt=example_prompt,
        steering_vector=traditional_diff,
        scale=1.5,
        max_new_tokens=60,
        temperature=0.7
    )
    logger.info(f"  {trad_example['text']}\n")

    logger.info("=" * 60)
    logger.info("Note: Compare how different steering vectors affect generation")
    logger.info("      - Dogs/Bridge should steer toward their concepts")
    logger.info("      - Combinations show how methods blend concepts")
    logger.info("      - Traditional diff shows contrastive baseline")
    logger.info("=" * 60)

    logger.info("\n" + "=" * 60)
    logger.info("CONCEPT PRESENCE EVALUATION")
    logger.info("=" * 60)
    logger.info(f"(measuring occurrences of concept-related keywords: {dog_tokens})\n")
    if 'baseline_avg' in scoring and 'steered_avg' in scoring:
        baseline_occurrences = scoring['baseline_avg']['avg_total_occurrences']
        steered_occurrences = scoring['steered_avg']['avg_total_occurrences']

        logger.info(f"Baseline avg keyword occurrences:  {baseline_occurrences:.2f}")
        logger.info(f"Steered avg keyword occurrences:   {steered_occurrences:.2f}")

        if baseline_occurrences > 0:
            improvement = ((steered_occurrences / baseline_occurrences) - 1) * 100
            logger.info(f"Improvement:                       {improvement:+.1f}%")

            if improvement > 50:
                logger.info("‚úÖ Strong steering effect detected")
            elif improvement > 0:
                logger.info("‚úì Moderate steering effect detected")
            else:
                logger.info("‚ö†Ô∏è Weak or no steering effect")

    logger.info("\n" + "=" * 60)
    logger.info("FILES SAVED")
    logger.info("=" * 60)
    logger.info(f"Steering vectors ({7} files):")
    logger.info(f"  {output_dir}/")
    logger.info(f"    - dogs_vector.pt")
    logger.info(f"    - bridge_vector.pt")
    logger.info(f"    - dogs_bridge_mean.pt")
    logger.info(f"    - dogs_bridge_max.pt")
    logger.info(f"    - dogs_bridge_rms.pt")
    logger.info(f"    - dogs_bridge_diff.pt")
    logger.info(f"    - traditional_diff.pt")

    logger.info(f"\nEvaluation results (3 JSON files):")
    logger.info(f"  {eval_output_dir}/")
    logger.info(f"    - dogs_probability_analysis.json")
    logger.info(f"    - dogs_generation_quality.json")
    logger.info(f"    - dogs_concept_scoring.json")

    logger.info("\n" + "=" * 60)
    logger.info("KEY FINDINGS")
    logger.info("=" * 60)
    logger.info("1. Null vector computed from average token embeddings")
    logger.info("2. Steering vectors created using null-diff method")
    logger.info("3. Multiple combination methods tested (mean, max, RMS-signed, diff)")
    if success:
        logger.info("4. ‚úÖ Null-vector steering validated - increases concept probabilities")
    else:
        logger.info("4. ‚ö†Ô∏è Validation results mixed - consider tuning parameters")
    logger.info("5. All results saved for further analysis")

    logger.info("\n" + "=" * 60)
    logger.info("NEXT STEPS")
    logger.info("=" * 60)
    logger.info("1. Review generated text in evaluation JSONs")
    logger.info("2. Compare different combination methods")
    logger.info("3. Try different scales and layers")
    logger.info("4. Test on your own concepts using DatasetBuilder")
    logger.info("5. Analyze probability shift patterns across scales")

    # ============================================================================
    # Done!
    # ============================================================================
    logger.info("\n" + "=" * 80)
    logger.info("EXPERIMENT COMPLETED SUCCESSFULLY! üéâ")
    logger.info("=" * 80)


if __name__ == "__main__":
    main()
